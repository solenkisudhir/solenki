{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from math import log\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example of [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "\n",
    "In **information retrieval**, `tf–idf or TFIDF`, short for `term frequency–inverse document frequency`, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus, It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf–idf is one of the most popular term-weighting schemes today; 83% of text-based recommender systems in digital libraries use tf–idf.\n",
    "\n",
    "Variations of the tf–idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query. tf–idf can be successfully used for stop-words filtering in various subject fields, including text summarization and classification.\n",
    "\n",
    "One of the simplest ranking functions is computed by summing the tf–idf for each query term; many more sophisticated ranking functions are variants of this simple model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Example of corpus\n",
    "2. Preprocessing and Tokenizing\n",
    "3. Calculating bag of words\n",
    "4. TF\n",
    "5. IDF\n",
    "6. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Simple example with Cats and Mouse',\n",
       " 'Another simple example with dogs and cats',\n",
       " 'Another simple example with mouse and cheese',\n",
       " 'Simple example with Cats and dogs']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "corpus = \"\"\"\n",
    "Simple example with Cats and Mouse\n",
    "Another simple example with dogs and cats\n",
    "Another simple example with mouse and cheese\n",
    "Simple example with Cats and dogs\n",
    "\"\"\".split(\"\\n\")[1:-1]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simple', 'example', 'with', 'cats', 'and', 'mouse'] ['another', 'simple', 'example', 'with', 'dogs', 'and', 'cats'] ['another', 'simple', 'example', 'with', 'mouse', 'and', 'cheese']\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "l_A = corpus[0].lower().split()\n",
    "l_B = corpus[1].lower().split()\n",
    "l_C = corpus[2].lower().split()\n",
    "\n",
    "print(l_A,l_B,l_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with', 'example', 'cats', 'simple', 'and', 'dogs', 'mouse', 'another', 'cheese'}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "word_set = set(l_A).union(set(l_B)).union(set(l_C))\n",
    "print(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with</th>\n",
       "      <th>example</th>\n",
       "      <th>cats</th>\n",
       "      <th>simple</th>\n",
       "      <th>and</th>\n",
       "      <th>dogs</th>\n",
       "      <th>mouse</th>\n",
       "      <th>another</th>\n",
       "      <th>cheese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   with  example  cats  simple  and  dogs  mouse  another  cheese\n",
       "0     1        1     1       1    1     0      1        0       0\n",
       "1     1        1     1       1    1     1      0        1       0\n",
       "2     1        1     0       1    1     0      1        1       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict_A = dict.fromkeys(word_set, 0)\n",
    "word_dict_B = dict.fromkeys(word_set, 0)\n",
    "word_dict_C = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in l_A:\n",
    "    word_dict_A[word] += 1\n",
    "\n",
    "for word in l_B:\n",
    "    word_dict_B[word] += 1\n",
    "\n",
    "for word in l_C: \n",
    "    word_dict_C[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict_A,word_dict_B, word_dict_C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple', 'example', 'with', 'cats', 'and', 'mouse']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 tf - Term Frequency\n",
    "In the case of the term frequency $tf(t,d)$, the simplest choice is to use the raw count of a term in a string. \n",
    "$${\\displaystyle \\mathrm {tf} (t,d)={\\frac {n_{t}}{\\sum _{k}n_{k}}}} $$\n",
    "where $n_t$ is the number of occurrences of the word $t$ in the string, and in the denominator - the total number of words in this string.\n",
    "\n",
    "**Example :** This is an Another Example \n",
    "\n",
    "<img src = 'https://lh3.googleusercontent.com/-4kZABcfu4uw/XjfrdNDf5OI/AAAAAAAAmgs/8i8tsCI8rsERNrm0P6WVrtaVT7I1wNvYgCK8BGAsYHg/s0/2020-02-03.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(word_dict, l):\n",
    "    tf = {}\n",
    "    sum_nk = len(l)\n",
    "    for word, count in word_dict.items():\n",
    "        tf[word] = count/sum_nk\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with': 0.16666666666666666,\n",
       " 'example': 0.16666666666666666,\n",
       " 'cats': 0.16666666666666666,\n",
       " 'simple': 0.16666666666666666,\n",
       " 'and': 0.16666666666666666,\n",
       " 'dogs': 0.0,\n",
       " 'mouse': 0.16666666666666666,\n",
       " 'another': 0.0,\n",
       " 'cheese': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_A = compute_tf(word_dict_A, l_A)\n",
    "tf_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with': 0.14285714285714285,\n",
       " 'example': 0.14285714285714285,\n",
       " 'cats': 0.14285714285714285,\n",
       " 'simple': 0.14285714285714285,\n",
       " 'and': 0.14285714285714285,\n",
       " 'dogs': 0.14285714285714285,\n",
       " 'mouse': 0.0,\n",
       " 'another': 0.14285714285714285,\n",
       " 'cheese': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_B = compute_tf(word_dict_B, l_B)\n",
    "tf_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with': 0.14285714285714285,\n",
       " 'example': 0.14285714285714285,\n",
       " 'cats': 0.0,\n",
       " 'simple': 0.14285714285714285,\n",
       " 'and': 0.14285714285714285,\n",
       " 'dogs': 0.0,\n",
       " 'mouse': 0.14285714285714285,\n",
       " 'another': 0.14285714285714285,\n",
       " 'cheese': 0.14285714285714285}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_C = compute_tf(word_dict_C, l_C)\n",
    "tf_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 idf - Inverse Document Frequency\n",
    "idf is a measure of how much information the word provides\n",
    "$$ \\mathrm{idf}(t, D) =  \\log \\frac{N}{|\\{d \\in D: t \\in d\\}|} $$\n",
    "- $N$: total number of strings in the corpus ${\\displaystyle N={|D|}}$\n",
    "- ${\\displaystyle |\\{d\\in D:t\\in d\\}|}$  : number of strings where the term ${\\displaystyle t}$ appears (i.e., ${\\displaystyle \\mathrm {tf} (t,d)\\neq 0})$. If the term is not in the corpus, this will lead to a division-by-zero. It is therefore common to adjust the denominator to ${\\displaystyle 1+|\\{d\\in D:t\\in d\\}|}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(strings_list):\n",
    "    n = len(strings_list)\n",
    "    idf = dict.fromkeys(strings_list[0].keys(), 0)\n",
    "    for l in strings_list:\n",
    "        for word, count in l.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, v in idf.items():\n",
    "        idf[word] = log(n / float(v))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with': 0.0,\n",
       " 'example': 0.0,\n",
       " 'cats': 0.4054651081081644,\n",
       " 'simple': 0.0,\n",
       " 'and': 0.0,\n",
       " 'dogs': 1.0986122886681098,\n",
       " 'mouse': 0.4054651081081644,\n",
       " 'another': 0.4054651081081644,\n",
       " 'cheese': 1.0986122886681098}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = compute_idf([word_dict_A, word_dict_B, word_dict_C])\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\# 6 tf-idf Term Frequency–Inverse Document Frequency\n",
    "Then tf–idf is calculated as\n",
    "$$ {\\displaystyle \\mathrm {tfidf} (t,d,D)=\\mathrm {tf} (t,d)\\cdot \\mathrm {idf} (t,D)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = dict.fromkeys(tf.keys(), 0)\n",
    "    for word, v in tf.items():\n",
    "        tf_idf[word] = v * idf[word]\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_A = compute_tf_idf(tf_A, idf)\n",
    "tf_idf_B = compute_tf_idf(tf_B, idf)\n",
    "tf_idf_C = compute_tf_idf(tf_C, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with</th>\n",
       "      <th>example</th>\n",
       "      <th>cats</th>\n",
       "      <th>simple</th>\n",
       "      <th>and</th>\n",
       "      <th>dogs</th>\n",
       "      <th>mouse</th>\n",
       "      <th>another</th>\n",
       "      <th>cheese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.156945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   with  example      cats  simple  and      dogs     mouse   another  \\\n",
       "0   0.0      0.0  0.067578     0.0  0.0  0.000000  0.067578  0.000000   \n",
       "1   0.0      0.0  0.057924     0.0  0.0  0.156945  0.000000  0.057924   \n",
       "2   0.0      0.0  0.000000     0.0  0.0  0.000000  0.057924  0.057924   \n",
       "\n",
       "     cheese  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.156945  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tf_idf_A, tf_idf_B, tf_idf_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For clustering we must use tf-idf weights\n",
    "the example above is just an example, in practice it is better to apply [TfidfVectorizer from sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full text for clusterring\n",
    "\n",
    "This corpus contain some strings about Google and some strings about TF-IDF from Wikipedia. Just for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\"\"\n",
    "Google and Facebook are strangling the free press to death. Democracy is the loser\n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "is a numerical statistic that is intended to reflect\n",
    "how important a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "NQ is aimed at enabling QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question. Systems will need to first decide whether the question is sufficiently well defined to be answerable — many questions make false assumptions or are just too ambiguous to be answered concisely. Then they will need to decide whether there is any part of the Wikipedia page that contains all of the information needed to infer the answer. We believe that the long answer identification task — finding all of the information required to infer an answer — requires a deeper level of language understanding than finding short answers once the long answers are known.\n",
    "\n",
    "It is our hope that the release of NQ, and the associated challenge, will help spur the development of more effective and robust QA systems. We encourage the NLU community to participate and to help close the large gap between the performance of current state-of-the-art approaches and a human upper bound. Please visit the challenge website to view the leaderboard and learn more.\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and tokenizing\n",
    "Firstly, we must bring every chars to lowercase and remove all punctuation, because it's not important for our task, but is very harmful for clustering algorithm. \n",
    "After that, we'll split strings to array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate tf-idf for this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                preprocessor=<function preprocessing at 0x000002797AB95A60>,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16x187 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 258 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = tfidf_vectorizer.fit_transform(all_text)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.30193189, 0.30193189, 0.        , ..., 0.        , 0.        ,\n",
       "        0.26294454],\n",
       "       [0.        , 0.        , 0.        , ..., 0.35843178, 0.        ,\n",
       "        0.31214881],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.07360375, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.30193189, 0.30193189, 0.        , ..., 0.        , 0.        ,\n",
       "         0.26294454],\n",
       "        [0.        , 0.        , 0.        , ..., 0.35843178, 0.        ,\n",
       "         0.31214881],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.07360375, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16x141 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf = count_vect.fit_transform(all_text)\n",
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 2, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16x141 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_weight = trans.fit_transform(sf)\n",
    "trans_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 141)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray(trans_weight.mean(axis=0).ravel().tolist())\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.021851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0.021851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aimed</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambiguous</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>android</td>\n",
       "      <td>0.057262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>visit</td>\n",
       "      <td>0.010237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>website</td>\n",
       "      <td>0.010237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>weighting</td>\n",
       "      <td>0.026982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>0.013422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>word</td>\n",
       "      <td>0.075714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Term   Weights\n",
       "0           18  0.021851\n",
       "1           60  0.021851\n",
       "2        aimed  0.006711\n",
       "3    ambiguous  0.006711\n",
       "4      android  0.057262\n",
       "..         ...       ...\n",
       "136      visit  0.010237\n",
       "137    website  0.010237\n",
       "138  weighting  0.026982\n",
       "139  wikipedia  0.013422\n",
       "140       word  0.075714\n",
       "\n",
       "[141 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_df = pd.DataFrame({'Term':count_vect.get_feature_names(),\n",
    "                         'Weights':weights.ravel()})\n",
    "weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>make</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>identification</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>understanding</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>comprehend</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>concisely</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>contain</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>contains</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>enabling</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>page</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>deeper</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Term   Weights\n",
       "75             make  0.006711\n",
       "54   identification  0.006711\n",
       "129   understanding  0.006711\n",
       "23       comprehend  0.006711\n",
       "24        concisely  0.006711\n",
       "25          contain  0.006711\n",
       "26         contains  0.006711\n",
       "38         enabling  0.006711\n",
       "88             page  0.006711\n",
       "31           deeper  0.006711"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_df.sort_values(by='Weights',ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train simple kmeans model with k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(tfidf)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_for_predicting = [\"tf and idf is awesome!\", \"some androids is there\"]\n",
    "kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.544302971981818"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.score(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
