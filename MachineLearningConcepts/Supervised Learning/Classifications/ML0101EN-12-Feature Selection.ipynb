{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the `prediction variable` or `output` in which you are interested.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/0/04/Feature_selection_Wrapper_Method.png)\n",
    "Having `irrelevant features` in your data can `decrease the accuracy` of many models, especially linear algorithms like linear and logistic regression.\n",
    "\n",
    "Three importance of performing feature selection before modeling your data are:\n",
    "\n",
    "1. **Reduces Overfitting**: Less redundant data means less opportunity to make decisions based on noise.\n",
    "2. **Improves Accuracy**: Less misleading data means modeling accuracy improves.\n",
    "3. **Reduces Training Time**: Less data means that algorithms train faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section lists 4 feature selection recipes for machine learning in Python\n",
    "1. **Univariate Selection**\n",
    "2. **Recursive Feature Elimination**\n",
    "3. **Principal Component Analysis**\n",
    "4. **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3,4,5,6]])\n",
    "y = np.array([0,3,6,9,12,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
    "1. The scikit-learn library provides the **SelectKBest** class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "2. Many different statistical test scan be used with this selection method. For example the **ANOVA F-value** method is appropriate for numerical inputs and categorical data, as we see in the Pima dataset. This can be used via the **f_classif()** function. We will select the 4 best features using this method in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with Univariate Statistical Tests\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "filename = 'https://raw.githubusercontent.com/reddyprasade/Data-Sets-For-Machine-Learnig-and-Data-Science/master/DataSets/pima-indians-diabetes.csv'\n",
    "dataframe = read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f_classif** --> ANOVA F-value between label/feature for classification tasks.\n",
    "\n",
    "**mutual_info_classif**--> Mutual information for a discrete target.\n",
    "\n",
    "**chi2**-->Chi-squared stats of non-negative features for classification tasks.\n",
    "\n",
    "**f_regression**--> F-value between label/feature for regression tasks.\n",
    "\n",
    "**mutual_info_regression**--> Mutual information for a continuous target.\n",
    "\n",
    "**SelectPercentile**--> Select features based on percentile of the highest scores.\n",
    "\n",
    "**SelectFpr** --> Select features based on a false positive rate test.\n",
    "\n",
    "**SelectFdr** -->Select features based on an estimated false discovery rate.\n",
    "\n",
    "**SelectFwe** --> Select features based on family-wise error rate.\n",
    "\n",
    "**GenericUnivariateSelect**-->Univariate feature selector with configurable mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "test = SelectKBest(score_func=f_classif, \n",
    "                   k=4)\n",
    "fit = test.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 39.67022739, 213.16175218,   3.2569504 ,   4.30438091,\n",
       "         13.28110753,  71.7720721 ,  23.8713002 ,  46.14061124]),\n",
       " array([5.06512730e-10, 8.93543165e-43, 7.15139001e-02, 3.83477048e-02,\n",
       "        2.86186460e-04, 1.22980749e-16, 1.25460701e-06, 2.20997546e-11]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.score_func(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.67  213.162   3.257   4.304  13.281  71.772  23.871  46.141]\n"
     ]
    }
   ],
   "source": [
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.  148.   33.6  50. ]\n",
      " [  1.   85.   26.6  31. ]\n",
      " [  8.  183.   23.3  32. ]\n",
      " [  1.   89.   28.1  21. ]\n",
      " [  0.  137.   43.1  33. ]]\n"
     ]
    }
   ],
   "source": [
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     39.670227\n",
       "1    213.161752\n",
       "2      3.256950\n",
       "3      4.304381\n",
       "4     13.281108\n",
       "5     71.772072\n",
       "6     23.871300\n",
       "7     46.140611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(fit.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the scores for each attribute and the 4 attributes chosen (those with the highest scores). Specifically features with indexes 0 (Pregnancies), 1 (plas), 5 (mass), and 7 (age)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Recursive Feature Elimination\n",
    "* The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\n",
    "\n",
    "* It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
    "\n",
    "* You can learn more about the RFE class in the [scikit-learn documentation.]()\n",
    "\n",
    "\n",
    "![](https://lh3.googleusercontent.com/-Kq_fnU7FHgc/XuQvTR5PKtI/AAAAAAAAonI/GQz_Nc8nwOsNPy5NNPjo0nYy9DzUtiiEwCK8BGAsYHg/s0/2020-06-12.png)\n",
    "\n",
    "\n",
    "The example below uses RFE with the logistic regression algorithm to select the top 3 features. The choice of algorithm does not matter too much as long as it is skillful and consistent.\n",
    "\n",
    "\n",
    "Feature selection refers to techniques that select a subset of the most relevant features (columns) for a dataset. Fewer features can allow machine learning algorithms to run more efficiently (less space or time complexity) and be more effective. Some machine learning algorithms can be misled by irrelevant input features, resulting in worse predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "model = LogisticRegression(solver='lbfgs',max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [ True False False False False  True  True False]\n",
      "Feature Ranking: [1 2 4 6 5 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(model, n_features_to_select=3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   BMI  DiabetesPedigreeFunction\n",
       "0            6  33.6                     0.627\n",
       "1            1  26.6                     0.351"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Rank 1 Features\")\n",
    "dataframe[['Pregnancies','BMI', 'DiabetesPedigreeFunction']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that RFE chose the the top 3 features as `Pregnancies`, `BMI` and `DiabetesPedigreeFunction`.\n",
    "\n",
    "These are marked True in the support_ array and marked with a choice “1” in the ranking_ array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Principal Component Analysis\n",
    "Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a compressed form.\n",
    "\n",
    "Generally this is called a data reduction technique. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result.\n",
    "\n",
    "In the example below, we use PCA and select 3 principal components.\n",
    "\n",
    "Learn more about the PCA class in scikit-learn by reviewing the PCA API. Dive deeper into the math behind PCA on the Principal Component Analysis Wikipedia article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.889 0.062 0.026]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.022e-03  9.781e-02  1.609e-02  6.076e-02  9.931e-01  1.401e-02\n",
      "   5.372e-04 -3.565e-03]\n",
      " [-2.265e-02 -9.722e-01 -1.419e-01  5.786e-02  9.463e-02 -4.697e-02\n",
      "  -8.168e-04 -1.402e-01]\n",
      " [-2.246e-02  1.434e-01 -9.225e-01 -3.070e-01  2.098e-02 -1.324e-01\n",
      "  -6.400e-04 -1.255e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the transformed dataset (3 principal components) bare little resemblance to the source data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Feature Importance\n",
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features.\n",
    "\n",
    "In the example below we construct a ExtraTreesClassifier classifier for the Pima Indians onset of diabetes dataset. You can learn more about the ExtraTreesClassifier class in the scikit-learn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.10\n",
      "Feature: 1, Score: 0.21\n",
      "Feature: 2, Score: 0.11\n",
      "Feature: 3, Score: 0.08\n",
      "Feature: 4, Score: 0.07\n",
      "Feature: 5, Score: 0.16\n",
      "Feature: 6, Score: 0.12\n",
      "Feature: 7, Score: 0.16\n"
     ]
    }
   ],
   "source": [
    "for I,v in enumerate(imp):\n",
    "    print('Feature: %0d, Score: %.2f' % (I,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVAklEQVR4nO3dYYxdZ53f8e9vDVFLIEpCJsGyTZ1FFsiqwEQjhyoSLU2DnLDC4UUkp22wUFZOpLgQdVHr8qKl6psUBaiQ0lgGXBkVsMJCFKu4hMil2qIl1OPUTeIEbwbXxBM79mzSEmgkjJN/X9wz27uX65lzZya+Duf7ka7uOc95nnP+J4ruz+eZc89NVSFJ6p4/GHcBkqTxMAAkqaMMAEnqKANAkjrKAJCkjnrLuAsYxVVXXVVr164ddxmS9KZy6NChv6yqicH2N1UArF27lqmpqXGXIUlvKkl+MazdKSBJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqqDfVN4F/X63d8f2xHfv4fR8b27EljZdXAJLUUQaAJHVUqwBIsinJ0STTSXYM2f6PkjzZvP48yQcWGpvkyiSPJXmueb9ieU5JktTGggGQZAXwAHAzsB64Pcn6gW7/C/i7VfV+4N8Au1qM3QEcqKp1wIFmXZJ0gbS5AtgITFfVsao6C+wFNvd3qKo/r6r/3aw+DqxuMXYzsKdZ3gPcuvjTkCSNqk0ArAJO9K3PNG3ncyfwn1uMvaaqTgE071cP21mSbUmmkkzNzs62KFeS1EabAMiQthraMfkIvQD456OOPZ+q2lVVk1U1OTHxOz9oI0lapDYBMAOs6VtfDZwc7JTk/cDXgM1V9VKLsaeTrGzGrgTOjFa6JGkp2gTAQWBdkmuTXAJsAfb1d0jybuB7wB1V9Rctx+4DtjbLW4FHFn8akqRRLfhN4Ko6l2Q78CiwAthdVUeS3N1s3wn8S+CdwL9PAnCumbYZOrbZ9X3AQ0nuBJ4Hblvmc5MkzaPVoyCqaj+wf6BtZ9/yHwN/3HZs0/4ScOMoxUqSlo/fBJakjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6qlUAJNmU5GiS6SQ7hmx/X5KfJPlNks/2tb83yeG+1ytJ7m22fT7JC33bblm+05IkLWTBXwRLsgJ4ALiJ3o+8H0yyr6qe6ev2MvBp4Nb+sVV1FNjQt58XgIf7uny5qu5f0hlIkhalzRXARmC6qo5V1VlgL7C5v0NVnamqg8Bv59nPjcDPq+oXi65WkrRs2gTAKuBE3/pM0zaqLcC3B9q2J3kyye4kVwwblGRbkqkkU7Ozs4s4rCRpmDYBkCFtNcpBklwCfBz4Tl/zg8B76E0RnQK+OGxsVe2qqsmqmpyYmBjlsJKkebQJgBlgTd/6auDkiMe5GXiiqk7PNVTV6ap6rapeB75Kb6pJknSBtAmAg8C6JNc2/5LfAuwb8Ti3MzD9k2Rl3+ongKdH3KckaQkWvAuoqs4l2Q48CqwAdlfVkSR3N9t3JnkXMAVcBrze3Oq5vqpeSfI2encQ3TWw6y8k2UBvOun4kO2SpDfQggEAUFX7gf0DbTv7ll+kNzU0bOyrwDuHtN8xUqWSpGXlN4ElqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOavUwOEm/P9bu+P7Yjn38vo+N7dj6XV4BSFJHeQUgSS2M88oJ3pirJ68AJKmjWgVAkk1JjiaZTrJjyPb3JflJkt8k+ezAtuNJnkpyOMlUX/uVSR5L8lzzfsXST0eS1NaCAZBkBfAAvR92Xw/cnmT9QLeXgU8D959nNx+pqg1VNdnXtgM4UFXrgAPNuiTpAmlzBbARmK6qY1V1FtgLbO7vUFVnquog8NsRjr0Z2NMs7wFuHWGsJGmJ2gTAKuBE3/pM09ZWAT9McijJtr72a6rqFEDzfvWwwUm2JZlKMjU7OzvCYSVJ82kTABnSViMc44aquo7eFNI9ST48wliqaldVTVbV5MTExChDJUnzaBMAM8CavvXVwMm2B6iqk837GeBhelNKAKeTrARo3s+03ackaenaBMBBYF2Sa5NcAmwB9rXZeZJLk7xjbhn4KPB0s3kfsLVZ3go8MkrhkqSlWfCLYFV1Lsl24FFgBbC7qo4kubvZvjPJu4Ap4DLg9ST30rtj6Crg4SRzx/pWVf2g2fV9wENJ7gSeB25b3lOTJM2n1TeBq2o/sH+gbWff8ov0poYGvQJ84Dz7fAm4sXWlkqRl5TeBJamjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI5qFQBJNiU5mmQ6yY4h29+X5CdJfpPks33ta5L8KMmzSY4k+Uzfts8neSHJ4eZ1y/KckiSpjQV/ESzJCuAB4CZ6PxB/MMm+qnqmr9vLwKeBWweGnwP+pKqeaH4b+FCSx/rGfrmq7l/yWUiSRtbmCmAjMF1Vx6rqLLAX2NzfoarOVNVB4LcD7aeq6olm+VfAs8CqZalckrQkbQJgFXCib32GRXyIJ1kLfBD4aV/z9iRPJtmd5IrzjNuWZCrJ1Ozs7KiHlSSdR5sAyJC2GuUgSd4OfBe4t6peaZofBN4DbABOAV8cNraqdlXVZFVNTkxMjHJYSdI82gTADLCmb301cLLtAZK8ld6H/zer6ntz7VV1uqpeq6rXga/Sm2qSJF0gbQLgILAuybVJLgG2APva7DxJgK8Dz1bVlwa2rexb/QTwdLuSJUnLYcG7gKrqXJLtwKPACmB3VR1JcnezfWeSdwFTwGXA60nuBdYD7wfuAJ5KcrjZ5eeqaj/whSQb6E0nHQfuWt5TkyTNZ8EAAGg+sPcPtO3sW36R3tTQoB8z/G8IVNUd7cuU1AVrd3x/rMc/ft/Hxnr8C81vAktSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRrR4Hre4a5+N5u/ZoXulC8wpAkjqqVQAk2ZTkaJLpJDuGbH9fkp8k+U2Sz7YZm+TKJI8lea55v2LppyNJamvBAEiyAngAuJnezzzenmT9QLeXgU8D948wdgdwoKrWAQeadUnSBdLmCmAjMF1Vx6rqLLAX2NzfoarOVNVB4LcjjN0M7GmW9wC3LvIcJEmL0CYAVgEn+tZnmrY25ht7TVWdAmjerx62gyTbkkwlmZqdnW15WEnSQtrcBTTsR92r5f6XMrbXuWoXsAtgcnJypLH9vJtFkv66NlcAM8CavvXVwMmW+59v7OkkKwGa9zMt9ylJWgZtAuAgsC7JtUkuAbYA+1ruf76x+4CtzfJW4JH2ZUuSlmrBKaCqOpdkO/AosALYXVVHktzdbN+Z5F3AFHAZ8HqSe4H1VfXKsLHNru8DHkpyJ/A8cNtyn5wk6fxafRO4qvYD+wfadvYtv0hveqfV2Kb9JeDGUYqVJC0fvwksSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJH+aPwetPyEd/S0ngFIEkdZQBIUkcZAJLUUQaAJHWUASBJHdUqAJJsSnI0yXSSHUO2J8lXmu1PJrmuaX9vksN9r1eaXwsjyeeTvNC37ZblPTVJ0nwWvA00yQrgAeAmej/yfjDJvqp6pq/bzcC65nU98CBwfVUdBTb07ecF4OG+cV+uqvuX40QkSaNpcwWwEZiuqmNVdRbYC2we6LMZ+Eb1PA5cnmTlQJ8bgZ9X1S+WXLUkacnaBMAq4ETf+kzTNmqfLcC3B9q2N1NGu5NcMezgSbYlmUoyNTs726JcSVIbbQIgQ9pqlD5JLgE+Dnynb/uDwHvoTRGdAr447OBVtauqJqtqcmJiokW5kqQ22gTADLCmb301cHLEPjcDT1TV6bmGqjpdVa9V1evAV+lNNUmSLpA2zwI6CKxLci29P+JuAf7hQJ999KZz9tL7I/Avq+pU3/bbGZj+SbKyr88ngKcXUb90UfI5RXozWDAAqupcku3Ao8AKYHdVHUlyd7N9J7AfuAWYBl4FPjU3Psnb6N1BdNfArr+QZAO9qaLjQ7ZLkt5ArZ4GWlX76X3I97ft7Fsu4J7zjH0VeOeQ9jtGqlSStKz8JrAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUa0CIMmmJEeTTCfZMWR7knyl2f5kkuv6th1P8lSSw0mm+tqvTPJYkuea9yuW55QkSW0sGABJVgAP0Pth9/XA7UnWD3S7GVjXvLYBDw5s/0hVbaiqyb62HcCBqloHHGjWJUkXSJsrgI3AdFUdq6qzwF5g80CfzcA3qudx4PIkKxfY72ZgT7O8B7h1hLolSUvUJgBWASf61meatrZ9CvhhkkNJtvX1uaaqTgE071ePUrgkaWna/Ch8hrTVCH1uqKqTSa4GHkvys6r6s7YFNqGxDeDd735322GSpAW0uQKYAdb0ra8GTrbtU1Vz72eAh+lNKQGcnpsmat7PDDt4Ve2qqsmqmpyYmGhRriSpjTYBcBBYl+TaJJcAW4B9A332AZ9s7gb6EPDLqjqV5NIk7wBIcinwUeDpvjFbm+WtwCNLPBdJ0ggWnAKqqnNJtgOPAiuA3VV1JMndzfadwH7gFmAaeBX4VDP8GuDhJHPH+lZV/aDZdh/wUJI7geeB25btrCRJC2rzNwCqaj+9D/n+tp19ywXcM2TcMeAD59nnS8CNoxQrSVo+fhNYkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6qlUAJNmU5GiS6SQ7hmxPkq80259Mcl3TvibJj5I8m+RIks/0jfl8kheSHG5etyzfaUmSFrLgT0ImWQE8ANwEzAAHk+yrqmf6ut0MrGte1wMPNu/ngD+pqieaH4c/lOSxvrFfrqr7l+90JElttbkC2AhMV9WxqjoL7AU2D/TZDHyjeh4HLk+ysqpOVdUTAFX1K+BZYNUy1i9JWqQ2AbAKONG3PsPvfogv2CfJWuCDwE/7mrc3U0a7k1wx7OBJtiWZSjI1OzvbolxJUhttAiBD2mqUPkneDnwXuLeqXmmaHwTeA2wATgFfHHbwqtpVVZNVNTkxMdGiXElSG20CYAZY07e+GjjZtk+St9L78P9mVX1vrkNVna6q16rqdeCr9KaaJEkXSJsAOAisS3JtkkuALcC+gT77gE82dwN9CPhlVZ1KEuDrwLNV9aX+AUlW9q1+Anh60WchSRrZgncBVdW5JNuBR4EVwO6qOpLk7mb7TmA/cAswDbwKfKoZfgNwB/BUksNN2+eqaj/whSQb6E0VHQfuWrazkiQtaMEAAGg+sPcPtO3sWy7gniHjfszwvw9QVXeMVKkkaVn5TWBJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpo1oFQJJNSY4mmU6yY8j2JPlKs/3JJNctNDbJlUkeS/Jc837F8pySJKmNBQMgyQrgAeBmYD1we5L1A91uBtY1r23Agy3G7gAOVNU64ECzLkm6QNpcAWwEpqvqWFWdBfYCmwf6bAa+UT2PA5c3P/o+39jNwJ5meQ9w6xLPRZI0gja/CbwKONG3PgNc36LPqgXGXlNVpwCq6lSSq4cdPMk2elcVAL9OcrRFzW+Eq4C/XMzA/NtlruR3WdviWNvi/F7WBm94feOs7W8Na2wTAMN+1L1a9mkzdl5VtQvYNcqYN0KSqaqaHHcdw1jb4ljb4ljb4lyMtbWZApoB1vStrwZOtuwz39jTzTQRzfuZ9mVLkpaqTQAcBNYluTbJJcAWYN9An33AJ5u7gT4E/LKZ3plv7D5ga7O8FXhkieciSRrBglNAVXUuyXbgUWAFsLuqjiS5u9m+E9gP3AJMA68Cn5pvbLPr+4CHktwJPA/ctqxntvzGPg01D2tbHGtbHGtbnIuutlSNNCUvSfo94TeBJamjDABJ6igDYAELPQZjnJLsTnImydPjrqVfkjVJfpTk2SRHknxm3DXNSfI3kvz3JP+zqe1fj7umQUlWJPkfSf7TuGsZlOR4kqeSHE4yNe565iS5PMmfJvlZ8//d3xl3TXOSvLf57zX3eiXJveOuC/wbwLyaR1n8BXATvVtaDwK3V9UzYy2skeTDwK/pfQv7b4+7njnNbb0rq+qJJO8ADgG3Xgz/3ZIEuLSqfp3krcCPgc8032C/KCT5p8AkcFlV/dG46+mX5DgwWVWL/kLTGyHJHuC/VdXXmjsO31ZV/2fcdQ1qPlNeAK6vql+Mux6vAObX5jEYY1NVfwa8PO46BlXVqap6oln+FfAsvW+Fj13zuJJfN6tvbV4Xzb+CkqwGPgZ8bdy1vFkkuQz4MPB1gKo6ezF++DduBH5+MXz4gwGwkPM94kItJVkLfBD46Xgr+f+aKZbD9L58+FhVXTS1Af8O+GfA6+Mu5DwK+GGSQ81jWi4GfwjMAv+hmTr7WpJLx13UeWwBvj3uIuYYAPNb8qMsuizJ24HvAvdW1SvjrmdOVb1WVRvofTN9Y5KLYvosyR8BZ6rq0LhrmccNVXUdvSf83tNMQ47bW4DrgAer6oPA/+UifLpwMzX1ceA7465ljgEwvzaPwdAQzfz6d4FvVtX3xl3PMM00wX8FNo25lDk3AB9v5tn3An8/yX8cb0l/XVWdbN7PAA/TmyYdtxlgpu9K7k/pBcLF5mbgiao6Pe5C5hgA82vzGAwNaP7Q+nXg2ar60rjr6ZdkIsnlzfLfBP4B8LPxVtVTVf+iqlZX1Vp6/6/9l6r6x2Mu668kubT5oz7NFMtHgbHfgVZVLwInkry3aboRGPsNB0PczkU0/QPtngbaWQs8ymLsknwb+HvAVUlmgH9VVV8fb1VA71+ydwBPNXPtAJ+rqv1jrGnOSmBPczfGHwAPVdVFd7vlReoa4OFevvMW4FtV9YPxlvRX/gnwzeYfasdoHkdzsUjyNnp3E9417lr6eRuoJHWUU0CS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkd9f8AdWHOI25+hFQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([x for x in range(len(imp))],imp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
